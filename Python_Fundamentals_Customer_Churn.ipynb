{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting Customer Churn\n",
        "\n",
        "\"Customer churn\" is a term used to describe when a company loses customers.  The example in this notebook involves a scenario familiar to many: switching mobile phone providers.  If my provider could identify my intent to switch early, it could entice me to stay with timely offers, such as a phone upgrade or a new service feature.\n",
        "\n",
        "Machine learning can help us identify patterns in the data for customers who left in the past, thus helping us prevent the same churn in the future.\n",
        "\n",
        "The data for this notebook is included in `churn.csv`."
      ],
      "metadata": {
        "id": "DaZ6f9v2jEkl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Setup\n",
        "\n",
        "Import the necessary libraries.  NOTE: If you're using an environment other than Google Colab, you may need to first install some of these using `!pip`.\n",
        "*   **pandas**: A library for organizing and manipulating data, making it easy to work with tables.\n",
        "*   **numpy**: A library for numerical computing in Python, providing support for large, multi-dimensional arrays and matrices, along with a collection of mathematical functions to operate on these arrays.\n",
        "*   **matplotlib**: A plotting library for Python, used to create static, animated, and interactive graphs and charts.\n",
        "*   **seaborn**: A statistical data visualization library built on top of matplotlib, offering a higher-level interface for drawing statistical graphics.\n",
        "*   **xgboost**: An optimized distributed gradient boosting library designed to be highly efficient, flexible, and portable, used for building machine learning models, especially for solving data science challenges involving structured data.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "o1gBblgWjmaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If you need to install libraries, you can do so using this syntax\n",
        "# !pip install xgboost"
      ],
      "metadata": {
        "id": "oLdP0F-984Jf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import xgboost as xgb"
      ],
      "metadata": {
        "id": "fRC1W2cgjqjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Data Cleansing and Exploratory Data Analysis\n",
        "\n",
        "It all starts with data.  Load the data from churn.csv into a DataFrame, then explore and visualize it to help us better understand what we're working with, and what will be most important to pass to the model when we train it."
      ],
      "metadata": {
        "id": "xbNJpomIjHsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD THE DATA\n",
        "\n",
        "# We'll use pandas to load the CSV data into a DataFrame\n",
        "# If using Google Colab, the file should be uploaded to /content folder\n",
        "churn = pd.read_csv('churn.csv')\n",
        "\n",
        "# Display the first five rows of the dataset to understand its structure\n",
        "churn.head()"
      ],
      "metadata": {
        "id": "XXfSiCgtjWdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CLEAN THE DATA\n",
        "\n",
        "# Check for missing values\n",
        "# If there are any missing values, you can fill them with a placeholder or drop them, depending on the context\n",
        "# We don't actually have missing values in this dataset, we'll just print\n",
        "print(churn.isnull().sum())\n",
        "\n",
        "# Standardize data for boolean columns, making everything \"True\" or \"False\"\n",
        "churn[\"Churn?\"] = churn[\"Churn?\"].map({'False.': False, 'True.': True})\n",
        "churn[\"Int'l Plan\"] = churn[\"Int'l Plan\"].map({'no': False, 'yes': True})\n",
        "churn[\"VMail Plan\"] = churn[\"VMail Plan\"].map({'no': False, 'yes': True})"
      ],
      "metadata": {
        "id": "VHTWnDobjlVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EXPLORE AND VISUALIZE THE DATA\n",
        "\n",
        "# Visualize the distribution of customer churn\n",
        "sns.countplot(x='Churn?', data=churn)\n",
        "plt.title('Distribution of Customer Churn')\n",
        "plt.show()\n",
        "\n",
        "# Calculate the percentage of churn\n",
        "churn_percentage = churn['Churn?'].value_counts(normalize=True) * 100\n",
        "# Print the percentage of customers who churned\n",
        "print(f\"Percentage of customers who churned: {churn_percentage[1]:.2f}%\")"
      ],
      "metadata": {
        "id": "HFlLNu49nzlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is some imbalance in the data, as only 14.49% of customers churned, but this is not extreme imbalance."
      ],
      "metadata": {
        "id": "WvnivVQDyutq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Histograms for each numeric features, to see how balanced the data is\n",
        "display(churn.describe())\n",
        "%matplotlib inline\n",
        "hist = churn.hist(bins=30, sharey=True, figsize=(10, 10))"
      ],
      "metadata": {
        "id": "Z0ryy0-_yQHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most numeric features are well-distributed, showing a bell-shaped (or Gaussian) distribution.  In machine learning, this normality is desired for optimal perforamnce of the algorithms.  The exceptions are `VMail Message` and `Area Code`, which we'll handle below."
      ],
      "metadata": {
        "id": "LEZAfR_Ky2hr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Frequency tables for each categorical feature\n",
        "for column in churn.select_dtypes(include=['object', 'bool']).columns:\n",
        "    # Using 'display' to show the DataFrame and 'pd.crosstab()' to create the frequency table\n",
        "    display(column, pd.crosstab(index=churn[column], columns='% observations', normalize='columns') * 100)  # Multiplying by 100 to convert to percentage"
      ],
      "metadata": {
        "id": "oIoNQsxRrx5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This exploration tells us:\n",
        "*   `State`: Fairly well distributed; we will check correlations later\n",
        "*   `Phone`: With all the unique values, it will be hard to use this as a feature.  We should drop this, along with `Area Code`, as it goes with `Phone`.\n",
        "*   `Int'l Plan`: We will  check correlations later\n",
        "*   `VMail Plan`: We will check correlations later\n",
        "*   `Churn`: The target feature; included here because it's a categorical feature (meaning it can take on just a fixed number of possible values)"
      ],
      "metadata": {
        "id": "vlFk0-dsvgMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop Area Code and Phone from the dataset\n",
        "churn = churn.drop(['Phone', 'Area Code'], axis=1)"
      ],
      "metadata": {
        "id": "psb3Cr2mvZ_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Two options to help visualize the correlation between features and Churn (heatmap and correlation matrix)\n",
        "# Correlation heatmap of numerical features\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(churn.corr(), annot=True, fmt=\".2f\")\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()\n",
        "\n",
        "# Calculate the correlation matrix, focusing on the Churn column\n",
        "correlation_matrix = churn.corr()\n",
        "churn_correlations = correlation_matrix[\"Churn?\"].sort_values(ascending=False)\n",
        "\n",
        "# Plotting the correlations with Churn\n",
        "plt.figure(figsize=(8, 10))\n",
        "sns.barplot(x=churn_correlations.values, y=churn_correlations.index)\n",
        "plt.title(\"Correlation with Churn\")\n",
        "plt.xlabel(\"Correlation Coefficient\")\n",
        "plt.show()\n",
        "\n",
        "churn_correlations"
      ],
      "metadata": {
        "id": "qDdos8ueqmr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This exploration tells us:\n",
        "\n",
        "*   `Int'l Plan`: There's a positive correlation (0.26) between having an international plan and churn, suggesting customers with international plans are more likely to churn. This could be due to various factors such as cost, satisfaction with international service, or other reasons that warrant further investigation.\n",
        "\n",
        "*   `CustServ Calls`: The number of customer service calls is positively correlated (0.21) with churn, indicating that customers who contact customer service more frequently are more likely to leave. This might reflect issues with service satisfaction or unresolved problems.\n",
        "\n",
        "*   `Day Mins` and `Day Charge`: Both of these features show a positive correlation (about 0.21) with churn, suggesting that higher day time usage (and the associated charges) could be a factor in customers' decision to churn.\n",
        "\n",
        "*   `VMail Plan` and `VMail Message`: These features are negatively correlated with churn (-0.10 and -0.09, respectively), indicating that customers who use voicemail services are less likely to churn. This could be interpreted as an indicator of customer engagement or satisfaction with the service.\n",
        "\n",
        "*   `Intl Calls`: Interestingly, the number of international calls is negatively correlated (-0.05) with churn, which might suggest that customers making more international calls are less likely to leave, contrasting with the positive correlation seen with having an international plan.\n"
      ],
      "metadata": {
        "id": "B1YxPNQgv8sI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatter matrix to visualize the relationship between non-target (i.e., \"Churn\") features\n",
        "pd.plotting.scatter_matrix(churn.select_dtypes(include=[np.number]), figsize=(12, 12), alpha=0.2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B3-u5QHqosJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This exploration tells us:\n",
        "\n",
        "\n",
        "*   Some features (the ones with a diagonal line on the scatter matrix) have a correlation of 100% with one another (such as Day Charge and Day Mins, Night Charge and Night Mins)\n",
        "*   Features like this can cause problems when we train the model later, so we'll remove the \"Charge\" features"
      ],
      "metadata": {
        "id": "jwPWABhwxDy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop features for Day Charge, Eve Charge, Night Charge, Intl Charge to remove the 100% correlation issue\n",
        "churn = churn.drop([\"Day Charge\", \"Eve Charge\", \"Night Charge\", \"Intl Charge\"], axis=1)"
      ],
      "metadata": {
        "id": "ZMQ29p-gxE2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode the State column so we have 0s and 1s rather than string data\n",
        "churn_encoded = pd.get_dummies(churn, columns=['State'])"
      ],
      "metadata": {
        "id": "vKOd9eq8l4i8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Building and Training the Model\n",
        "\n",
        "In this section, we split the data into training, validation and test sets.  Then we build the model, inputting various parameters.  Finally, we train the model on the training dataset, evaluting it with the validation dataset."
      ],
      "metadata": {
        "id": "hES5mqbz7deu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training, validation and test sets\n",
        "\n",
        "# Randomly shuffle the dataset and split it into training (70%), validation (20%), and testing (10%) sets\n",
        "train_data, validation_data, test_data = np.split(churn_encoded.sample(frac=1, random_state=1729),\n",
        "                                                  [int(0.7 * len(churn)), int(0.9 * len(churn))])"
      ],
      "metadata": {
        "id": "ekkh_oHE7tcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming the last column \"Churn?\" is the target variable\n",
        "# Separate the features and the target variable for each dataset\n",
        "X_train = train_data.drop(\"Churn?\", axis=1)\n",
        "y_train = train_data[\"Churn?\"]\n",
        "X_val = validation_data.drop(\"Churn?\", axis=1)\n",
        "y_val = validation_data[\"Churn?\"]\n",
        "X_test = test_data.drop(\"Churn?\", axis=1)\n",
        "y_test = test_data[\"Churn?\"]\n",
        "\n",
        "# Convert the datasets into DMatrix format for XGBoost\n",
        "# XGBoost works well with DMatrix, a data structure optimized for both memory efficiency and training speed\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dval = xgb.DMatrix(X_val, label=y_val)\n",
        "dtest = xgb.DMatrix(X_test, label=y_test)"
      ],
      "metadata": {
        "id": "zSbg7hti9X4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify parameters for the model\n",
        "params = {\n",
        "    'max_depth': 3,  # The maximum depth of the decision tree; can be adjusted (typically ranges 3-10)\n",
        "    'eta': 0.1,  # The learning rate (how much the model adjusts itself in response to errors); can be adjusted\n",
        "    'objective': 'binary:logistic',  # We're choosing this because it's a binary problem (customers either churn or they don't)\n",
        "                                     # Logistic means it will output a probability (the probability that a customer will leave)\n",
        "    'eval_metric': 'auc',  # Evaluation metrics for validation data, e.g., \"auc\" or \"Area Under the Curve\" for binary classification\n",
        "}\n",
        "num_rounds = 100  # The number of rounds for boosting\n"
      ],
      "metadata": {
        "id": "LfPU-wAw-ke-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model using the training dataset and evaluate it using the validation dataset\n",
        "evallist = [(dval, 'eval'), (dtrain, 'train')]\n",
        "bst = xgb.train(params, dtrain, num_rounds, evallist)"
      ],
      "metadata": {
        "id": "DUfi4IPY_dvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AUC values range from 0 to 1. A model whose predictions are 100% wrong has an AUC of 0.0; one whose predictions are 100% correct has an AUC of 1.0.\n",
        "AUC values between 0.5 and 1.0 indicate useful models. A value of 0.5 suggests a model that does no better than random chance.\n",
        "\n",
        "Higher AUC values indicate better model performance. In our model, the AUC for both the evaluation set (eval-auc) and the training set (train-auc) increases over the iterations, suggesting the  model is learning and improving its ability to distinguish between the classes over time.\n"
      ],
      "metadata": {
        "id": "cxtmqvTwDrom"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Evaluating the Model\n",
        "\n"
      ],
      "metadata": {
        "id": "xNnUKulpEdxo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initially, the gap between training and evaluation AUC is somewhat moderate, but it starts to widen significantly as training progresses. For instance, towards the end (around iteration 99), the train-auc is at 0.97169 while the eval-auc is at 0.87690. This growing gap may suggest that the model is beginning to overfit the training data-â€”meaning it's getting better at predicting the training data, but not the evaluation data.  This suggests that the model is fitting more to the idiosyncrasies of the training data rather than capturing generalizable patterns that apply to unseen data.\n",
        "\n",
        "**Actions to Consider**:\n",
        "\n",
        "**Early Stopping**: Implement early stopping to halt the training process once the evaluation metric stops improving for a specified number of rounds. XGBoost supports early stopping.\n",
        "\n",
        "**Regularization**: Increase regularization parameters (lambda, alpha) to penalize more complex models and thus mitigate overfitting.\n",
        "\n",
        "**Parameter Tuning**: Adjust other hyperparameters, like max_depth, min_child_weight, and subsample, to help control model complexity and fit.\n",
        "\n",
        "**Cross-Validation**: Use XGBoost's built-in cross-validation method to assess model performance more robustly. This might give you a better indication of how the model will perform on unseen data.\n",
        "\n",
        "**Feature Engineering**: Revisit your features to ensure they're relevant and not leading to overfitting. Removing irrelevant or highly correlated features can sometimes improve model generalizability."
      ],
      "metadata": {
        "id": "LDF5IWcPEo0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing early stopping (i.e., train the model to learn from data until it stops getting better)\n",
        "\n",
        "bst = xgb.train(\n",
        "    params,\n",
        "    dtrain,\n",
        "    num_boost_round=1000,  # Set to a high number intentionally; training may stop much earlier\n",
        "    evals=[(dval, \"eval\")],\n",
        "    early_stopping_rounds=10  # Stops after 10 rounds of no improvement on the eval dataset\n",
        ")\n",
        "\n",
        "# After training, you can access the best iteration\n",
        "# This is the number of the training round where the model performed the best on the validation dataset before it stopped improving\n",
        "# We'll use this in the next code block\n",
        "print(f\"Best iteration: {bst.best_iteration}\")\n"
      ],
      "metadata": {
        "id": "uvQU3CzeFMGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with the test dataset on the final (best) model\n",
        "\n",
        "# Predicting the probabilities for the positive class (\"Churn\")\n",
        "y_pred_proba = bst.predict(dtest, iteration_range=(0, bst.best_iteration + 1))\n",
        "\n",
        "# The scikit-learn library is great for calculating AUC and other metrics, though this could also be calculated manually\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Print the final AUC score\n",
        "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
        "print(f\"Final AUC on Test Dataset: {auc_score:.3f}\")"
      ],
      "metadata": {
        "id": "HOvCm2OcQWG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "An AUC score of over 0.9 is often considered excellent in many applications. It indicates strong differentiation between the positive and negative classes in the dataset, suggesting that the model has a good predictive ability for the task at hand."
      ],
      "metadata": {
        "id": "n8V_yIT2Q--5"
      }
    }
  ]
}